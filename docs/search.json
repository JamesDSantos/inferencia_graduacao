[
  {
    "objectID": "teste.html",
    "href": "teste.html",
    "title": "5  Testes de hipóteses",
    "section": "",
    "text": "5.1 Definição de hipóteses, testes e modos de avaliação\nExistem diversos problemas nos quais o objetivo da inferência é levantar evidências de alguma suposição sobre a população \\(F(.)\\). Tais suposições são denominadas hipóteses.\nPodem existir diferentes hipóteses para o mesmo problema. É comum identificar a \\(i\\)-ésima hipótese por \\(H_i\\), com \\(i=0,1,2,\\ldots\\). Seguem alguns exemplos:\nNesse curso, será discutida apenas a abordagem paramétrica. Sob essa ótica, hipóteses são suposições sobre os parâmetros da população, o que implica em hipóteses do tipo \\[H_i:\\theta\\in \\Theta_I\\subset\\Theta.\\] Nesta abordagem, existem dois tipos importantes de hipóteses: * Hipóteses simples: são do tipo \\(H:\\theta=\\theta_0\\). Exemplos: \\(H_0:\\theta=\\theta_0\\); \\(H_1:\\{\\alpha=\\alpha_0\\}\\cap\\{\\beta=\\beta_0\\}\\). Uma hipótese simples identifica completamente a população. * Hipóteses compostas: são do tipo \\(H:\\theta\\in \\Theta'\\subset \\Theta\\). Exemplos: \\(H_0:\\theta\\leq \\theta_0\\); \\(H_1:\\{\\alpha\\leq\\alpha_0\\}\\cup\\{\\beta\\geq\\beta_0\\}\\). Observe que essas hipóteses trazem muitas possibilidades para o valor de \\(\\theta\\), tornando impossível determinar completamente a população.\nOs testes de hipóteses são procedimentos que utilizam uma amostra para decidir se certa hipótese é verdadeira ou falsa. Ao considerar uma certa hipótese \\(H_0:\\theta\\in\\Theta_0\\), onde \\(\\Theta_0\\subset \\Theta\\), após observar os dados existem duas decisões: * Decisão 1: aceitar a hipótese \\(H_0\\) como verdadeira. * Decisão 2: aceitar a hipótese \\(H_0\\) como falsa. Note que estas decisões são estatísticas, uma vez que elas são baseadas na amostra.\nPara racionalizar o processo de decisão, seja\n\\[\\delta=\\left\\{\\begin{array}{ll}1,& \\hbox{ se $H_0$ é falsa }\\\\ 0,&\\hbox{ se $H_0$ é verdadeira}\\end{array}\\right.\\] Observe que o teste \\(D\\) pode ser considerado um estimador para \\(\\delta\\). Deste modo, a qualidade do teste \\(D\\) pode ser verificada através do erro quadrático médio:\n\\[\\begin{align}EQM_{D}(\\delta)&=E(D-\\delta)^2=\\delta^2P(D=0|\\delta)+(1-\\delta)^2P(D=1|\\delta)\\\\\n&= \\delta^2(1-P(D=1|\\delta))+(1-\\delta)^2 P(D=1|\\delta)\\\\\n&=\\delta^2+[-\\delta^2+(1-\\delta)^2]P(D=1|\\delta)\\\\\n&=\\delta^2+[1-2\\delta]P(D=1|\\delta)\\end{align}\\]\nObserve que o erro quadrático médio depende de \\(P(D=1|\\delta)\\), que por sua vez só é conhecido quando \\(\\delta\\) é conhecido. Ao ver essa probabilidade como função de \\(\\delta\\), temos a função poder do teste (posteriormente definiremos apropriadamente essa função).\nConsidere os seguintes cenários:\n\\[EQM_D(0)=P(D=1|\\delta=0)\\] e quanto menor o valor do poder do teste, menor é o erro quadrático médio. É imediato que essa probabilidade se refere à ação de rejeitar, erroneamente, a hipótese \\(H_0\\) quando ela é verdadeira. Esse erro é denominado erro do tipo I.\nObserve que não é possível eliminar a ocorrência de um dos erros (tipo I ou II) sem correr o risco de sempre cometer o outro erro. Para ter algum controle sobre o problema, escolhemos a probabilidade de cometer o erro tipo I para ficar controlada. Tal probabilidade é denominada nível de significância.\nUma vez que decidimos controlar o erro do tipo I, mantendo o nível de significância em \\(\\alpha\\), sabemos que nosso teste \\(D\\) vai cometer o erro de rejeitar \\(H_0\\) com probabilidade \\(\\alpha\\) sempre que \\(H_0\\) for verdadeira. Como apenas esse cenário está controlado, é comum formular a hipótese \\(H_0\\) como algo que deve ser rejeitado (daí vem o termo “hipótese nula” para ser referir à \\(H_0\\)).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Testes de hipóteses</span>"
    ]
  },
  {
    "objectID": "teste.html#definição-de-hipóteses-testes-e-modos-de-avaliação",
    "href": "teste.html#definição-de-hipóteses-testes-e-modos-de-avaliação",
    "title": "5  Testes de hipóteses",
    "section": "",
    "text": "Definição. Qualquer suposição sobre \\(F(.)\\) é denominada\n\n\nExemplo. Seja \\(X_1,\\ldots,X_n\\) uma amostra de variáveis aleatórias. Ao menos que existam razões físicas claras, considerar que estas variáveis são independentes e identicamente distribuídas é uma hipótese.\n\n\n\n\\(H_1:\\theta=0\\).\n\\(H_2:\\theta&gt;0\\).\n\\(H_3:\\) \\(X_1,\\ldots,X_n\\sim\\hbox{Normal}(\\mu,\\sigma^2)\\) para algum par \\((\\mu,\\sigma^2)\\) desconhecido.\n\\(H_4:\\) \\(X_1,\\ldots,X_n\\) é uma amostra de variáveis aleatórias independentes.\n\\(H_5:\\) \\(X_1,\\ldots,X_n\\) é uma amostra de variáveis aleatórias independentes com distribuição normal.\n\n\n\n\nTeste de Hipóteses. Um teste de hipóteses (também chamado de regra de decisão) é qualquer estatística \\(D:\\mathcal{X}^n\\rightarrow \\{0,1\\}\\). Se \\(D(\\textbf{x})=1\\), toma-se a decisão de rejeitar \\(H_0\\) e se \\(D(\\textbf{x})=0\\), toma-se a decisão de não rejeitar \\(H_0\\).\n\n\n\n\n\n\n\nSe \\(\\delta=0\\) (a hipótese é verdadeira), teremos\n\n\n\nSe \\(\\delta=1\\) ( a hipótese é falsa), então \\[EQM_D(1)=1-P(D=1|\\delta=1),\\] e, nesse caso, quanto maior o valor do poder do teste, menor é o erro quadrático médio. Obviamente, \\(1-P(D=1|\\delta=1)=P(D=0|\\delta=1)\\). Portanto, o erro quadrático médio é definido como a probabilidade de não rejeitar (erroneamente) a hipótese \\(H_0\\) quando ela é falsa. Esse erro é denominado erro do tipo II.\n\n\nImportante! Os erros do tipo I e II não são complementares, uma vez que o primeiro é calculado sob \\(\\delta=0\\) e o segundo sob \\(\\delta=1\\). Contudo, há uma relação importante entre eles, ilustrada nos cenários abaixo:\n\nSuponha que o teste \\(D\\) nunca comete o erro do tipo I. Então \\(P(D=1|\\delta=0)=0\\). Isso só pode acontecer se a decisão \\(D=1\\) nunca for realizada. Logo, quando \\(\\delta=1\\), \\[1-P(D=1|\\delta=1)=P(D=0|\\delta=1)=1\\] e o erro do tipo II será cometido com probabilidade 1.\nAlternativamente, suponha que o teste \\(D\\) nunca comete o erro do tipo II. Então \\(P(D=0|\\delta=1)=0\\). Isso só pode acontecer se a decisão \\(D=0\\) nunca for realizada. Logo, quando \\(\\delta=0\\), \\[0=P(D=0|\\delta=0)=1-P(D=1|\\delta=0)\\Rightarrow P(D=1|\\delta=0)=1\\] e o erro do tipo I será cometido com probabilidade 1.\n\n\n\n\nDefinição Dizemos que o teste \\(D\\) tem nível de significância \\(\\alpha\\) se a probabilidade de cometer o erro do tipo I é menor ou igual à \\(\\alpha\\).\n\n\n\nExemplo. Dizemos que certa máquina está desregulada se sua probabilidade (\\(\\theta\\)) de produzir itens defeituosos é maior que \\(0,001\\). Um lote de peças produzidos por essa máquina é separado e cada peça é testada. O objetivo é saber se a máquina está regulada, ou seja, se a atual probabilidade é menor que \\(0,001\\). Recorde que é usual definir a hipótese nula como o complementar do que queremos testar, o que gera \\[H_0:\\theta\\geq 0,001\\;\\; (\\hbox{ máquina desregulada})\\]\nVejamos os riscos envolvidos nesse processo de decisão:\n\nErro tipo I: dizemos que a máquina está operando normalmente, quando na verdade ela está desregulada. Os lotes serão vendidos, os clientes serão prejudicados, a marca vai perder credibilidade, pode ser necessário fazer o recall dos lotes produzidos.\nErro tipo II: dizemos que a máquina está desregulada, quando na verdade ela está operando normalmente. A linha de produção deve ser interrompida e a equipe técnica tem que avaliar a máquina. O problema se resolve dentro da própria empresa.\n\nPara testar essa hipóte, escolhemos um teste \\(D\\) com nível de significância de 1%. Ao observar a amostra, duas coisas podem acontecer:\n\n\\(D(\\textbf{x})=1\\). Nesse caso, assumimos que a máquina está operando normalmente. Tomamos essa decisão porque a probabilidade do teste errar nessa situação é de 1%\n\\(D(\\textbf{x})=0\\). Nesse caso, assumimos que a máquina está desregulada. A probabilidade do erro tipo II em geral é maior que o nível de significância (no nosso caso 1%). Ainda sim, cometer esse erro implica em acionar a equipe técnica para uma avaliação, algo muito menos problemático que o erro do tipo I.\n\n\n\nImportante! Embora \\(D(x)=0\\) seja a decisão de aceitar \\(H_0\\) como verdadeira, alguns textos utilizam termos como “não há evidências para rejeitar \\(H_0\\)”, ou “o teste falhou em rejeitar \\(H_0\\)”. O motivo por trás desses termos está o fato de que o erro tipo II não está controlado, logo, não sabemos com que frequência a decisão de aceitar a hipótese vai estar equivocada.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Testes de hipóteses</span>"
    ]
  },
  {
    "objectID": "teste.html#a-construção-de-um-teste-de-hipóteses-a-partir-de-uma-estatística-de-teste",
    "href": "teste.html#a-construção-de-um-teste-de-hipóteses-a-partir-de-uma-estatística-de-teste",
    "title": "5  Testes de hipóteses",
    "section": "5.2 A construção de um teste de hipóteses a partir de uma estatística de teste",
    "text": "5.2 A construção de um teste de hipóteses a partir de uma estatística de teste\nPara construir um teste de hipóteses, é preciso particionar o espaço amostral de duas regiões:\n\nRegião de rejeição: são todas as amostras que levam à decisão de rejeitar a hipótese nula.\nRegião de aceitação: são todas as amostras que levam à decisão de aceitar a hipótese nula.\n\nPode ser uma tarefa árdua descobrir como particionar o espaço amostral de maneira adequada para obter um teste de hipóteses. Conforme já discutido no Capítulo 3, podemos utilizar uma estatística \\(T\\) para reduzir a dimensão do problema. Uma vez que o teste \\(D\\) e a estatística \\(T\\) são funções da amostra, podemos definir um teste com a composição \\(D(T(\\textbf{x}))\\). Quando utilizada dessa forma, \\(T\\) é denominada estatística de teste. A figura abaixo ilustra esse conceito.\n\n\n\nA estatística \\(T\\) utilizada como estatística de teste. As partições em verde formam as regiões de rejeição e as partições laranjas as de aceitação.\n\n\nEm geral, escolhemos uma estatística de teste que possui alguma relação com \\(\\theta\\) (como, por exemplo, uma estatística suficiente ou um estimador). Tal opção é útil para definir como a partição será feita. Para ilustrar, considere que \\(T\\) é um estimador para \\(\\theta\\) e suponha que desejamos testar se \\(H_0:\\theta\\in \\Theta_0\\). É natural pensar que \\(H_0\\) é falsa se \\(t\\) observado está longe da região \\(\\Theta_0\\). Deste modo, podemos definir um valor \\(c&gt;\\theta_0\\) e construir a região de rejeição \\[R=\\{t:t&gt;c\\}.\\] Deste modo, criamos o teste \\[D(t)=\\left\\{\\begin{array}{ll}1,&t&gt;c\\\\0,&t\\leq c\\end{array}\\right.\\] Para determinar o valor de \\(c\\), podemos fixar o nível de significância. Deste modo, teremos que \\[\\alpha=P(D=1|\\theta_0)=P(T&gt;c|\\theta_0)=1-F_{T|\\theta_0}(c)\\Rightarrow F_{T|\\theta_0}(c)=1-\\alpha.\\] Portanto, \\(c\\) é o quantil \\(1-\\alpha\\) da distribuição de \\(T\\) supondo que \\(\\theta=\\theta_0\\).\n\nExemplo. Seja \\(X_1,\\ldots,X_n\\) uma amostra aleatória da população Normal(\\(\\mu\\),1). Considere a hipótese nula \\(H_0:\\mu \\leq \\mu_0\\).\nSabemos que \\(\\bar{X}_n\\) é um estimador para \\(\\mu\\). Vamos ter evidências para rejeitar \\(H_0\\) quando \\[\\bar{x}_n&gt;c&gt;\\mu_0.\\]. Para determinar o valor de \\(c\\), fixe o nível de significância \\(\\alpha\\). Então\n\\[\\alpha=P(\\bar{X}_n&gt;c|\\mu_0)=1-P(\\bar{X}_n\\leq c|\\mu_0)\\Rightarrow F_{\\bar{X}_n|\\mu_0}(c)=1-\\alpha.\\] Portanto, \\(c\\) é o quantil \\(1-\\alpha\\) de de \\(\\bar{X}_n|\\mu_0\\sim N(\\mu_0,1/n)\\). Os exemplos\n\nExemplo. Um agricultor afirma que a média de produção de soja em sua fazenda maior que 3 toneladas por hectare. Uma amostra de 15 hectares foi selecionada e a produção de soja média foi de 3,2 toneladas. Supondo que a produção média de soja por hectare tem distribuição normal com desvio padrão de 0,5 tonelada por hectare, teste, ao nível de 5% de significância, a afirmação do agricultor.\nSolução. Queremos saber se \\(\\mu&gt;3\\). Portanto, a hipótese nula é \\[H_0:\\mu\\leq 3.\\] Vamos utilizar o estimador \\(\\bar{x}_{15}\\). A figura abaixo aprenta várias possibilidade para a distribuição de \\(\\bar{X}_{15}\\) quando \\(H_0\\) é verdadeira, sendo que a curva mais à direita corresponde à distribuição normal com média \\(\\mu=3\\). Os pontos verdes representam valores que podem ocorrer quando a hipótese nula é verdadeira. Já os pontos vermelhos ocorrem com uma probabilidade muito baixa quando \\(H_0\\) é verdadeira. Nosso objetivo é encontrar o ponto \\(c\\) que vai particionar os valores de \\(\\bar{x}_{15}\\), criando as regiões de rejeição e aceitação.\n\n\n\n\n\n\n\n\n\n\n\n\nAs funções densidade acima são apenas algumas das infinitas possibilidades de distribuição para \\(\\bar{X}_{15}\\) quando \\(H_0:\\mu\\leq 3\\).\n\nObserveOVamos rejeitar a hipótese nula se houverem evidências de que \\(\\mu\\) é maior que 3.\nUtilizando \\(\\bar{x}_{15}\\) para tomar a decisão, teremos a seguinte região de rejeição: \\[R=\\{\\bar{x}_{15}:\\bar{x}_{15}&gt;c\\}.\\] Para determinar o valor de \\(c\\), observe que \\[0,05=P(\\bar{X}_{15}&gt;c|\\mu=3)=1-P(\\bar{X}_{15}\\leq c|\\mu=3)\\Rightarrow F_{\\bar{X}_{15}|\\mu=3}(c)=0,95\\] logo \\(c\\) é o quantil de 95% da distribuição \\[\\bar{X}_{15}|\\mu=3\\sim N\\left(3,\\frac{0,5^2}{15}\\right)=N\\left(3,\\frac{1}{60}\\right)\\] O valor de \\(c=3,212\\). Portanto, rejeitamos \\(H_0\\) quando \\(\\bar{x}_{15}&gt;3,212\\). Como \\(\\bar{x}_{15}=3,2\\), não rejeitamos a hipótese nula.\n\n\n\nExemplo. O número de chamadas em um call center possui distribuição Poisson com taxa 120 chamadas. Após a implementação de uma nova campanha de marketing, a empresa deseja verificar se a taxa média de chamadas aumentou. Para isso, foi coletada uma nova amostra de dados, correspondente a 100 horas de atendimento, resultando em uma média de 135 chamadas por hora. Teste, ao nível de significância de 5%, se a nova campanha teve efeito.\nSolução. Deseja-se saber se houve aumento na taxa de chamadas, ou seja, se \\(\\theta&gt;120\\). Portanto, a hipótese nula pode ser formulada como \\(H_0:\\theta\\leq 120\\).\nConsiderando o estimador de máxima verossimilhança como estatística de teste, rejeitamos a hipótese nula quando \\(\\hat{\\theta}&gt;c\\), com \\(c&gt;120\\). Fixando o nível de significância em 5%, teremos que \\[0,05=P(\\hat{\\theta}&gt;c|\\theta=120)=1-P(\\hat{\\theta}\\leq c|\\theta=120)\\] e, como \\[P(\\hat{\\theta}\\leq c|\\theta)=P\\left(\\sum_{i=1}^{100}X_i\\leq 100c|\\theta=120\\right)=F_T(100c),\\] onde \\(T\\sim\\hbox{Poisson}(12000)\\). Unindo as duas equações acima, concluímos que, \\[F_T(100c)=0,95\\] ou seja \\(100c\\) é o quantil 95% da distribuição Poisson(12000). Abaixo apresentamos o cálculo de \\(c\\) no R:\n\nc = qpois(.95,12000)/100\nc\n\n[1] 121.8\n\n\nPortanto, a região de rejeição desse teste é \\[R=\\{\\hat{\\theta}:\\hat{\\theta}&gt;121,8\\}.\\] Como o valor observado de \\(\\hat{\\theta}\\) é \\(135\\), rejeitamos a hipótese nula. Portanto, há evidências de que a campanha teve efeito.\n\n\nExemplo. Uma fábrica de lâmpadas precisa manter a proporção de peças defeituosas no máximo em 2%. Regularmente, uma equipe de controle de qualidade seleciona aleatoriamente uma amostra de 500 lâmpadas para testar essa hipótese. Em determinado dia, foram encontras 15 lâmpadas com defeito. Verifique se há evidências de que a afirmação da fábrica é verdadeira, ao nível de 5% de significância.\nSolução. Precisamos determinar qual dos seguintes erros é o pior:\n\nDizer que a proporção de produção de peças é menor que 2%, quando na verdade é maior.\nDizer que a proporção de produção de peças é maior que 2%, quando na verdade é menor.\n\nO primeiro erro implica em problemas com clientes e propaganda negativa da marca. Já o segundo implica apenas no trabalho de rotina do controle de qualidade. Vamos considerar o primeiro como o erro do tipo I. Sendo \\(\\theta\\) a probabilidade de produzir uma lâmpada defeituosa, queremos testar \\[H_0:\\theta\\leq 0,02.\\]\nTemos uma amostra de 500 variáveis com distribuição Bernoulli, onde \\(X_i=1\\) se a lâmpada \\(i\\) for defeituosa. Observe que vamos ter evidências contra \\(H_0\\) quando \\(\\hat{\\theta}\\) for maior que 0,02\nA estimativa para \\(\\theta\\) encontrada foi \\[\\hat{\\theta}_{500}=\\sum_{i=1}^{500}\\frac{x_i}{500}=\\frac{15}{500}=0,03\\]\nVamos rejeitar\nEnunciado:\nCom base nessa amostra, podemos afirmar, com 95% de confiança, que a taxa de defeitos da fábrica é superior a 2%?",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Testes de hipóteses</span>"
    ]
  },
  {
    "objectID": "teste.html#o-teste-da-razão-de-verossimilhanças",
    "href": "teste.html#o-teste-da-razão-de-verossimilhanças",
    "title": "5  Testes de hipóteses",
    "section": "5.3 O teste da razão de verossimilhanças",
    "text": "5.3 O teste da razão de verossimilhanças\nConsidere a \\(H_0:\\theta\\in\\Theta_0\\subset \\Theta\\). Seja \\(\\hat{\\theta}_0\\), o valor em \\(\\Theta_0\\) tal que \\[\\begin{equation}\nL(\\theta)\\leq L(\\hat{\\theta}_0),\n\\end{equation}\\]\npara todo \\(\\theta\\in\\Theta_0\\). O valor \\(\\hat{\\theta}_0\\) pode ser interpretado como sendo a estimativa de máxima verossimilhança de \\(\\theta\\) quando a hipótese \\(H_0\\) é verdadeira.\nAgora, seja \\(\\hat{\\theta}\\) o EMV para \\(\\theta\\). Se \\(L(\\hat{\\theta}_0)\\) estiver próximo do valor de \\(L(\\hat{\\theta})\\), então o valor mais verossímil de \\(\\Theta_0\\) está próximo do valor mais verossímil de \\(\\Theta\\), dando evidências de que \\(H_0\\) é verdadeira. Portanto, valores pequenos da estatística \\[\\begin{align}\n\\lambda(\\textbf{X})=\\frac{L(\\hat{\\theta}_0)}{L(\\hat{\\theta})},\n\\end{align}\\] dão evidências de que \\(H_0\\) é falsa.\n\n\n\n\n\n\n\n\n\n\n\n\nA região cinza corresponde ao conjunto da hipótese nula. No gráfico da esquerda, o ponto mais verossímil da hipótese nula está afastado da estimativa de máxima verossimilhança, levando à rejeição de \\(H_0\\). Já no gráfico seguinte, a estimativa de máxima verossimilhança está dentro do conjunto da hipótese nula e, portanto, não hà motivos para rejeitá-la.\n\n\nDefinição Considere a hipótese \\(H_0:\\theta\\in\\Theta_0\\subset \\Theta\\). O teste para esta hipótese que utiliza a estatística \\[\\lambda(\\textbf{X})=\\frac{L(\\hat{\\theta}_0)}{\\hat{\\theta}}\\] com região de rejeição dada por \\[R=\\{ \\lambda(\\textbf{x}): \\lambda(\\textbf{x})\\leq k \\}\\] para algum valor de \\(0&lt;k&lt;1\\) fixado é denominado Teste da Razão de Verossimilhanças (TRV). \\end{defi}\nEm geral, o valor de \\(k\\) da região de rejeição dada na Definição \\(\\ref{defi::TRV}\\) é escolhido de modo a satisfazer \\[\\alpha\\geq P(\\lambda({\\bm{X}})&lt;k|\\theta),\\;\\;\\forall \\theta\\in\\Theta_0\\] para o nível de significância \\(\\alpha\\) fixado.\n{\n\n5.4 A função poder e os testes mais poderosos",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Testes de hipóteses</span>"
    ]
  },
  {
    "objectID": "teste.html#a-função-poder-e-os-testes-mais-poderosos",
    "href": "teste.html#a-função-poder-e-os-testes-mais-poderosos",
    "title": "5  Testes de hipóteses",
    "section": "5.4 A função poder e os testes mais poderosos",
    "text": "5.4 A função poder e os testes mais poderosos",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Testes de hipóteses</span>"
    ]
  }
]