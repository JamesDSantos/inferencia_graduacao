---
title: "Testes de hipóteses"
---


## Definição de hipóteses, testes e modos de avaliação

Existem diversos problemas nos quais o objetivo da inferência é levantar evidências de alguma suposição sobre a população $F(.)$. Tais suposições são denominadas hipóteses.

<div class='alert laert-success'>
**Definição.** Qualquer suposição sobre $F(.)$ é denominada 
</div>

<div class='alert laert-info'>
**Exemplo.**
Seja $X_1,\ldots,X_n$ uma amostra de variáveis aleatórias. 
Ao menos que existam razões físicas claras, considerar que estas variáveis são independentes e identicamente distribuídas é uma hipótese.
</div>

Podem existir diferentes hipóteses para o mesmo problema. É comum identificar a $i$-ésima hipótese por $H_i$, com $i=0,1,2,\ldots$. Seguem alguns exemplos:

* $H_1:\theta=0$.
* $H_2:\theta>0$.
* $H_3:$ $X_1,\ldots,X_n\sim\hbox{Normal}(\mu,\sigma^2)$ para algum par $(\mu,\sigma^2)$ desconhecido.
* $H_4:$ $X_1,\ldots,X_n$ é uma amostra de variáveis aleatórias independentes.
* $H_5:$ $X_1,\ldots,X_n$ é uma amostra de variáveis aleatórias independentes com distribuição normal.

Nesse curso, será discutida apenas a abordagem paramétrica. Sob essa ótica, hipóteses são suposições sobre os parâmetros da população, o que implica em hipóteses do tipo $$H_i:\theta\in \Theta_I\subset\Theta.$$ Nesta abordagem, existem dois tipos importantes de hipóteses:
* Hipóteses simples: são do tipo $H:\theta=\theta_0$. Exemplos: $H_0:\theta=\theta_0$; $H_1:\{\alpha=\alpha_0\}\cap\{\beta=\beta_0\}$. Uma hipótese simples identifica completamente a população.
* Hipóteses compostas: são do tipo $H:\theta\in \Theta'\subset \Theta$. Exemplos: $H_0:\theta\leq \theta_0$; $H_1:\{\alpha\leq\alpha_0\}\cup\{\beta\geq\beta_0\}$. Observe que essas hipóteses trazem muitas possibilidades para o valor de $\theta$, tornando impossível determinar completamente a população.

Os testes de hipóteses são procedimentos que utilizam uma amostra para decidir se certa hipótese é verdadeira ou falsa. 
Ao considerar uma certa hipótese $H_0:\theta\in\Theta_0$,  onde $\Theta_0\subset \Theta$, após observar os dados existem duas decisões:
* Decisão 1: aceitar a hipótese $H_0$ como verdadeira.
* Decisão 2: aceitar a hipótese $H_0$ como falsa.
Note que estas decisões são estatísticas, uma vez que elas são baseadas na amostra.

<div class='alert alert-success'>
**Teste de Hipóteses.** 
Um  teste de hipóteses (também chamado de regra de decisão) é qualquer estatística $D:\mathcal{X}^n\rightarrow \{0,1\}$. Se
$D(\textbf{x})=1$, toma-se a decisão de rejeitar $H_0$ e se $D(\textbf{x})=0$, toma-se a decisão de não rejeitar $H_0$. 
</div>


Para racionalizar o processo de decisão, seja

$$\delta=\left\{\begin{array}{ll}1,& \hbox{ se $H_0$ é falsa }\\ 0,&\hbox{ se $H_0$ é verdadeira}\end{array}\right.$$
Observe que o teste $D$ pode ser considerado um estimador para $\delta$. Deste modo, a qualidade do teste $D$ pode ser verificada através do erro quadrático médio:

$$\begin{align}EQM_{D}(\delta)&=E(D-\delta)^2=\delta^2P(D=0|\delta)+(1-\delta)^2P(D=1|\delta)\\
&= \delta^2(1-P(D=1|\delta))+(1-\delta)^2 P(D=1|\delta)\\
&=\delta^2+[-\delta^2+(1-\delta)^2]P(D=1|\delta)\\
&=\delta^2+[1-2\delta]P(D=1|\delta)\end{align}$$

Observe que o erro quadrático médio depende de $P(D=1|\delta)$, que por sua vez só é conhecido quando $\delta$ é conhecido. Ao ver essa probabilidade como função de $\delta$, temos a função poder do teste (posteriormente definiremos apropriadamente essa função).

Considere os seguintes cenários:

* Se $\delta=0$ (a hipótese é verdadeira), teremos 

$$EQM_D(0)=P(D=1|\delta=0)$$
e quanto menor o valor do poder do teste, menor é o erro quadrático médio. É imediato que essa probabilidade se refere à ação de rejeitar, erroneamente, a hipótese $H_0$ quando ela é verdadeira. Esse erro é denominado **erro do tipo I**.

* Se $\delta=1$ ( a hipótese é falsa), então
$$EQM_D(1)=1-P(D=1|\delta=1),$$
e, nesse caso, quanto maior o valor do poder do teste, menor é o erro quadrático médio. Obviamente, $1-P(D=1|\delta=1)=P(D=0|\delta=1)$. Portanto, o erro quadrático médio é definido como a probabilidade de não rejeitar (erroneamente) a hipótese $H_0$ quando ela é falsa. Esse erro é denominado **erro do tipo II.** 


<div class='alert alert-warning'>
**Importante!** Os erros do tipo I e II não são complementares, uma vez que o primeiro é calculado sob $\delta=0$ e o segundo sob $\delta=1$. Contudo, há uma relação importante entre eles, ilustrada nos cenários abaixo:

1. Suponha que o teste $D$ nunca comete o erro do tipo I. Então 
$P(D=1|\delta=0)=0$. Isso só pode acontecer se a decisão $D=1$ nunca for realizada. Logo, quando $\delta=1$, 
$$1-P(D=1|\delta=1)=P(D=0|\delta=1)=1$$
e o erro do tipo II será cometido com probabilidade 1.

2. Alternativamente, suponha que o teste $D$ nunca comete o erro do tipo II. Então 
$P(D=0|\delta=1)=0$. Isso só pode acontecer se a decisão $D=0$ nunca for realizada. Logo, quando $\delta=0$, 
$$0=P(D=0|\delta=0)=1-P(D=1|\delta=0)\Rightarrow P(D=1|\delta=0)=1$$
e o erro do tipo I será cometido com probabilidade 1.
</div>

Observe que não é possível eliminar a ocorrência de um dos erros (tipo I ou II) sem correr o risco de sempre cometer o outro erro. Para ter algum controle sobre o problema, escolhemos a probabilidade de cometer o erro tipo I para ficar controlada. Tal probabilidade é denominada nível de significância.

<div class='alert alert-success'>
**Definição** Dizemos que o teste $D$ tem nível de significância $\alpha$ se a probabilidade de cometer o erro do tipo I é menor ou igual à $\alpha$. 
</div>

Uma vez que decidimos controlar o erro do tipo I, mantendo o nível de significância em $\alpha$,  sabemos que nosso teste $D$ vai cometer o erro de rejeitar $H_0$ com probabilidade $\alpha$ sempre que $H_0$ for verdadeira. Como apenas esse cenário está controlado, é comum formular a hipótese $H_0$ como algo que **deve ser rejeitado** (daí vem o termo "hipótese nula" para ser referir à $H_0$).

<div class='alert alert-info'>
**Exemplo.** Dizemos que certa máquina está desregulada se sua probabilidade ($\theta$) de produzir itens defeituosos é maior que $0,001$. Um lote de peças produzidos por essa máquina é separado e cada peça é testada. O objetivo é saber se a máquina está regulada, ou seja, se a atual probabilidade é menor que $0,001$. Recorde que é usual definir a hipótese nula como o complementar do que queremos testar, o que gera
$$H_0:\theta\geq 0,001\;\; (\hbox{ máquina desregulada})$$

Vejamos os riscos envolvidos nesse processo de decisão:

* Erro tipo I: dizemos que a máquina está operando normalmente, quando na verdade ela está desregulada. Os lotes serão vendidos, os clientes serão prejudicados, a marca vai perder credibilidade, pode ser necessário fazer o recall dos lotes produzidos.

* Erro tipo II: dizemos que a máquina está desregulada, quando na verdade ela está operando normalmente. A linha de produção deve ser interrompida e a equipe técnica tem que avaliar a máquina. O problema se resolve dentro da própria empresa.

Para testar essa hipóte, escolhemos um teste  $D$ com nível de significância de 1%. Ao observar a amostra, duas coisas podem acontecer:

* $D(\textbf{x})=1$. Nesse caso, assumimos que a máquina está operando normalmente. Tomamos essa decisão porque a probabilidade do teste errar nessa situação é de 1%

* $D(\textbf{x})=0$. Nesse caso, assumimos que a máquina está desregulada. A probabilidade do erro tipo II em geral é maior que o nível de significância (no nosso caso 1%). Ainda sim, cometer esse erro implica em acionar a equipe técnica para uma avaliação, algo muito menos problemático que o erro do tipo I.

</div>


<div class='alert alert-warning'>
**Importante!** Embora $D(x)=0$ seja a decisão de aceitar $H_0$ como verdadeira, alguns textos utilizam termos como "não há evidências para rejeitar $H_0$", ou "o teste falhou em rejeitar $H_0$". O motivo por trás desses termos está o fato de que o erro tipo II não está controlado, logo, não sabemos com que frequência a decisão de aceitar a hipótese vai estar equivocada. 
</div>

## A construção de um teste de hipóteses a partir de uma estatística de teste

Para construir um teste de hipóteses, é preciso particionar o espaço amostral de duas regiões:

* Região de rejeição: são todas as amostras que levam à decisão de rejeitar a hipótese nula.

* Região de aceitação: são todas as amostras que levam à decisão de aceitar a hipótese nula.

Pode ser uma tarefa árdua descobrir como particionar o espaço amostral de maneira adequada para obter um teste de hipóteses. Conforme já discutido no Capítulo 3, podemos utilizar uma estatística $T$ para reduzir a dimensão do problema. Uma vez que o teste $D$ e a estatística $T$ são funções da amostra, podemos definir um teste com a composição $D(T(\textbf{x}))$. Quando utilizada dessa forma, $T$ é denominada *estatística de teste*. A figura abaixo ilustra esse conceito.

![A estatística $T$ utilizada como estatística de teste. As partições em verde formam as regiões de rejeição e as partições laranjas as de aceitação.  ](fig_stat_test.jpg){#fig::stat_test}

Em geral, escolhemos uma estatística de teste que possui alguma relação com $\theta$ (como, por exemplo, uma estatística suficiente ou um estimador). Tal opção é útil para definir como a partição será feita. Para ilustrar,  considere que $T$ é um estimador para $\theta$ e suponha que desejamos testar se $H_0:\theta\in \Theta_0$. Como $T$ é um estimador para $\theta$, pelo princípio das substituição, é razoável inferir que não se deve rejeitar $H_0$ se $T\in\Theta_0.$ Nas próximas 3 figuras, discutimos melhor essas ideias. Nelaas, mostramos o espaço paramétrico $\Theta$ e o espaço da hipótese nula $\Theta_0$ (região em salmão). O ponto em laranja é o verdadeiro valor do parâmetro. Em tons diferentes de verde, temos a densidade da estatística $T$, sendo que quanto mais escura, maior é a probabilidade de observar $t$ naquela região. Temos as seguintes situações:

* Na figura abaixo, a distribuição da estatística de teste gera somente valores dentro de $\Theta_0$. Portanto, sempre vamos inferir que $\theta\in\Theta_0$ e é razoável aceitar $H_0$.

![Nesse exemplo, os valores de $T$ sempre são gerados dentro do espaço da hipótese nula.  ](fig_testA.jpg){#fig::stat_testB}


* Na figura abaixo, a distribuição da estatística de teste nunca gera valores dentro de $\Theta_0$. Portanto, sempre vamos inferir que $\theta\notin\Theta_0$ e rejeitamos $H_0$.

![Nesse exemplo, os valores de $T$ nunca são gerados dentro do espaço da hipótese nula.  ](fig_testB.jpg){#fig::stat_testB}


* Nesta figura, a hipótese ainda é verdadeira, mas existe a possibilidade da estatística de teste gerar valores fora do espaço da hipótese nula. É nessa situação que é possível cometer o erro tipo I.

![Aqui, a hipótese nula é verdadeira, mas é possível observar $t\notin\Theta_0$.  ](fig_testc.jpg){#fig::stat_testC}

* A discussão realizada na última figura foi feita para um único ponto na borda de $\Theta_0$. Como não sabemos qual ponto é o correto, devemos levar em consideração a borda toda, conforme mostra a figura abaixo. Qualquer ponto $t$ gerado na região mais verde claro pode ter sido gerado supondo que a hipótese nula é verdadeira.

![Considerando todas as possibilidades para a hipótesen ula, valores de $t$ dentro de $\Theta_0$ ou na área verde podem ser gerados quando $H_0$ é verdadeira.  ](fig_testD.jpg){#fig::stat_testD}

* Agora, podemos particionar o espaço, criando uma região de rejeição e outra de aceitação. Como sempre devemos ter uma probabilidade baixa de cometer o erro tipo I, devemos colocar parte da área verde dentro da região de rejeição. Na figura abaixo, aceitamos $H_0$ quando $t$ está dentro do círculo vermelho e rejeitamos em caso contrário.

![Partição do espaço. A área dentro do círculo vermelho é a região de aceitação, que compreende a região $\Theta_0$ e a maioria dos valores de $T$ que podem ser gerados quando $H_0$ é verdadeira. A área fora do círculo vermelho inclui os pontos impossíveis e alguns pontos pouco prováveis de serem gerados por quando $H_0$ é verdadeira.](fig_testE.jpg){#fig::stat_testD}




<div class='alert alert-info'>
**Exemplo.** Seja $X_1,\ldots,X_{n}$ uma amostra aleatória da população Normal$(\mu,1)$. Suponha que desejamos testar $H_0:\mu=\mu_0$. 

Sabemos que $\bar{X}_{n}$ é um estimador para $\mu$. Se $\bar{x}_{n}=\mu_0$, não temos motivos para rejeitar $H_0$. Abaixo, mostramos a distribuição de $\bar{X}_{n}\sim N(\mu_0,1/n)$. É possível notar que para qualquer valor de $\bar{x}_{n}$ muito distantes, onde a cauda da normal é praticamente é praticamente nula, nos leva a rejeitar $H_0$ (uma vez que é improvável que esses valores sejam gerados se $H_0$ fosse verdadeira). Naturalmente, devemos escolher dois pontos, $a$ e $b$ tais que rejeitaremos $H_0$ sempre que $\bar{x}_{n}<a$ ou $\bar{x}_n>b$.

```{r echo = FALSE}
oo <- par(cex = 1.3)
plot.new()
plot.window( xlim=c(-5,5), ylim=c(0,.4))
polygon( c(seq(-5,-1.96,length=10),seq(-1.96,-5,length=10)), c(dnorm(seq(-5,-1.96,length=10)), rep(0,10)),col='gray')
polygon( c(seq(5,1.96,length=10),seq(1.96,5,length=10)), c(dnorm(seq(5,1.96,length=10)), rep(0,10)),col='gray')
curve(dnorm(x), add=T,lwd =2)
axis(1,at=c(-5,-1.96,0,1.96,5), labels=c('','a',expression(mu[0]),'b',''))

par(oo)
```

Como precisamos ter chance de cometer o erro tipo I, fixamos o nível de significância em $\alpha$ e em seguida escolhemos dois pontos $a,b$ ($a<b$) tais que

$$\alpha=P(\bar{X}_n\leq a\hbox{ ou }\bar{X}_n\geq b|\mu_0,1/n)=P(\bar{X}_n\leq a|\mu_0,1/n)+P(\bar{X}_n\geq b|\mu_0,1/n)$$

Fazendo 
$$\frac{\alpha}{2}=P(\bar{X}_n\leq a|\mu_0,1/n),$$
teremos que $a$ é o quantil $\alpha/2$ da distribuição Normal($\mu_0,1/n$). Fazendo 
$$\frac{\alpha}{2}=P(\bar{X}_n\geq b|\mu_0,1/n)\Rightarrow \frac{\alpha}{2}=P(\bar{X}_n\leq b|\mu_0,1/n)=1-\frac{\alpha}{2}$$
teremos que $b$ é o quantil $1-\alpha/2$ da distribuição Normal($\mu_0,1/n$). Portanto, nosso teste de hipóteses é:

$$D(\bar{x}_n)=\left\{\begin{array}{ll}1,&\hbox{ se \bar{x}_n<a\hbox{ ou }\bar{x}_n>b} \\
0,&\hbox{ se a\leq \bar{x}_n \leq b}\end{array}\right.$$
</div>
<div class='alert alert-info'>
**Exemplo.** Um agricultor afirma que a média de produção de soja em sua fazenda maior que 3 toneladas por hectare. Uma amostra de 15 hectares foi selecionada e a produção de soja média foi de 3,2 toneladas. Supondo que a produção média de soja por hectare tem distribuição normal com desvio padrão de 0,5 tonelada por hectare, teste, ao nível de 5% de significância, a afirmação do agricultor.

**Solução.** Queremos saber se $\mu>3$. Portanto, a hipótese nula é
$$H_0:\mu\leq 3.$$
Vamos utilizar o estimador $\bar{x}_{15}$. A figura abaixo aprenta várias possibilidade para a distribuição de $\bar{X}_{15}$ quando $H_0$ é verdadeira, sendo que a curva mais à direita corresponde à distribuição normal com média $\mu=3$. Os pontos verdes representam valores que podem ocorrer quando a hipótese nula é verdadeira. Já os pontos vermelhos ocorrem com uma probabilidade muito baixa quando $H_0$ é verdadeira. Nosso objetivo é encontrar o ponto $c$ que vai particionar os valores de $\bar{x}_{15}$, criando as regiões de rejeição e aceitação.

::: {#fig}
::: {.figure-content}
```{r echo = FALSE}
plot.new()
plot.window( xlim=c(-3,12), ylim=c(0,.4) )
polygon( c(seq(qnorm(.95,3),12,length=15),
           seq(12,qnorm(.95,3),length=15)),
         c( dnorm(seq(qnorm(.95,3),12,length=15),3),  rep(0,15)), col = 'salmon' )
curve( dnorm(x,3,1), add =T, lwd = 2)
curve( dnorm(x,2,1), add =T, lty = 2)
curve( dnorm(x,1,1), add =T, lty = 2)
curve( dnorm(x,0,1), add =T, lty = 2)
axis(1,at=c(-3,3,qnorm(.95,3,1),12), labels=c('',3,'c',''))
title( xlab= expression(bar(x)[15]))
points(-3,0, pch=16, col = 'green4')
points(-2,0, pch=16, col = 'green4')
points(-.5,0, pch=16, col = 'green4')
points(-1,0, pch=16, col = 'green4')
points(.4,0, pch=16, col = 'green4')
points(1.4,0, pch=16, col = 'green4')
points(3,0, pch=16, col = 'green4')
points(3.2,0, pch=16, col = 'green4')
abline(v=qnorm(.95,3,1))
#points(qnorm(.95,3,1),0, pch=16, col = 'red')
points(qnorm(.95,3,1)+.5,0, pch=16, col = 'red')
points(qnorm(.95,3,1)+2,0, pch=16, col = 'red')
points(qnorm(.95,3,1)+3,0, pch=16, col = 'red')
points(qnorm(.95,3,1)+4,0, pch=16, col = 'red')


```
:::
As funções densidade acima são apenas algumas das infinitas possibilidades de distribuição para $\bar{X}_{15}$ quando $H_0:\mu\leq 3$. 
:::


Utilizando $\bar{x}_{15}$ para tomar a decisão, teremos a seguinte região de rejeição:
$$R=\{\bar{x}_{15}:\bar{x}_{15}>c\}.$$
Para determinar o valor de $c$, observe que
$$0,05=P(\bar{X}_{15}>c|\mu=3)=1-P(\bar{X}_{15}\leq c|\mu=3)\Rightarrow F_{\bar{X}_{15}|\mu=3}(c)=0,95$$
logo $c$ é o quantil de 95% da distribuição $$\bar{X}_{15}|\mu=3\sim N\left(3,\frac{0,5^2}{15}\right)=N\left(3,\frac{1}{60}\right)$$
O valor de $c=3,212$. Portanto, rejeitamos $H_0$ quando $\bar{x}_{15}>3,212$. Como $\bar{x}_{15}=3,2$, não rejeitamos a hipótese nula.
</div>



<div class='alert alert-info'>
**Exemplo.** O número de chamadas em um call center possui distribuição Poisson com taxa 120 chamadas. Após a implementação de uma nova campanha de marketing, a empresa deseja verificar se a taxa média de chamadas aumentou. Para isso, foi coletada uma nova amostra de dados, correspondente a 100 horas de atendimento, resultando em uma média de 135 chamadas por hora. Teste, ao nível de significância de 5%, se a nova campanha teve efeito.

**Solução.** Deseja-se saber se houve aumento na taxa de chamadas, ou seja, se $\theta>120$. Portanto, a hipótese nula pode ser formulada como $H_0:\theta\leq 120$.

Considerando o estimador de máxima verossimilhança como estatística de teste, rejeitamos a hipótese nula quando
$\hat{\theta}>c$, com $c>120$. Fixando o nível de significância em 5%, teremos que
$$0,05=P(\hat{\theta}>c|\theta=120)=1-P(\hat{\theta}\leq c|\theta=120)$$
e, como
$$P(\hat{\theta}\leq c|\theta)=P\left(\sum_{i=1}^{100}X_i\leq 100c|\theta=120\right)=F_T(100c),$$
onde $T\sim\hbox{Poisson}(12000)$. Unindo as duas equações acima, concluímos que,
$$F_T(100c)=0,95$$
ou seja $100c$ é o quantil 95% da distribuição Poisson(12000). Abaixo apresentamos o cálculo de $c$ no `R`:

```{r}
c = qpois(.95,12000)/100
c
```
Portanto, a região de rejeição desse teste é $$R=\{\hat{\theta}:\hat{\theta}>121,8\}.$$
Como o valor observado de $\hat{\theta}$ é $135$, rejeitamos a hipótese nula. Portanto, há evidências de que a campanha teve efeito.
</div>


## O teste da razão de verossimilhanças

Considere a $H_0:\theta\in\Theta_0\subset \Theta$. Seja $\hat{\theta}_0$, o valor em $\Theta_0$ tal que
$$\begin{equation}
L(\theta)\leq L(\hat{\theta}_0),
\end{equation}$$

para todo $\theta\in\Theta_0$. O valor $\hat{\theta}_0$ pode ser interpretado como sendo a estimativa de máxima verossimilhança de $\theta$ quando a hipótese $H_0$ é verdadeira.

Agora, seja $\hat{\theta}$ o EMV para $\theta$. Se $L(\hat{\theta}_0)$ estiver próximo do valor de $L(\hat{\theta})$, então o valor mais verossímil de $\Theta_0$ está próximo do valor mais verossímil de $\Theta$, dando evidências de que $H_0$ é verdadeira. Portanto, valores pequenos da estatística 
$$\begin{align}
\lambda(\textbf{X})=\frac{L(\hat{\theta}_0)}{L(\hat{\theta})},
\end{align}$$
dão evidências de que $H_0$ é falsa.

::: {#fig}

::: {.figure-content}
```{r echo = FALSE}
oo <- par( mfrow = c(1,2), cex = 1.2)
plot.new()
plot.window( xlim = c(-3,3), ylim=c(0,.4))
polygon( c(seq(-3,-1,length =20 ),seq(-1,-3,length=20)),
          c(dnorm(seq(-3,-1,length =20 )), rep(0,20)), col='gray')                            
curve(dnorm(x), add= T, lwd = 2)
axis(1, at=c(-3,-1,0,3), 
labels=c('',expression(theta[0]),expression(hat(theta)),''))
axis(2, at=c(0,.4),labels = c('',''))
title( xlab= expression(theta), ylab=expression(L(theta)))

plot.new()
plot.window( xlim = c(-3,3), ylim=c(0,.4))
polygon( c(seq(-3,1,length =20 ),seq(1,-3,length=20)),
          c(dnorm(seq(-3,1,length =20 )), rep(0,20)), col='gray')                            
curve(dnorm(x), add= T, lwd = 2)
axis(1, at=c(-3,1,0,3), 
labels=c('',expression(theta[0]),expression(hat(theta)),''))
axis(2, at=c(0,.4),labels = c('',''))
title( xlab= expression(theta), ylab=expression(L(theta)))

par(oo)
```
:::
A região cinza corresponde ao conjunto da hipótese nula. No gráfico da esquerda, o ponto mais verossímil da hipótese nula está afastado da estimativa de máxima verossimilhança, levando à rejeição de $H_0$. Já no gráfico seguinte, a estimativa de máxima verossimilhança está dentro do conjunto da hipótese nula e, portanto, não hà motivos para rejeitá-la.
:::

<div class='alert alert-success'>
*Definição* Considere a hipótese $H_0:\theta\in\Theta_0\subset \Theta$. O teste para esta hipótese que utiliza a estatística 
$$\lambda(\textbf{X})=\frac{L(\hat{\theta}_0)}{\hat{\theta}}$$ com região de rejeição dada por
$$R=\{ \lambda(\textbf{x}): \lambda(\textbf{x})\leq k \}$$ para algum valor de $0<k<1$ fixado é denominado Teste da Razão de Verossimilhanças (TRV).
\end{defi}

Em geral, o valor de $k$ da região de rejeição dada na Definição \ref{defi::TRV} é escolhido de modo a satisfazer
$$\alpha\geq P(\lambda({\bm{X}})<k|\theta),\;\;\forall \theta\in\Theta_0$$
para o nível de significância $\alpha$ fixado.

\begin{exem}Seja $X_1\sim\hbox{Exponencial}(1/\theta)$, cuja densidade é
$$f(x|\theta)=\frac{1}{\theta}e^{-x/\theta},$$
com $x,\theta>0$ e considere a hipótese $$H_0:\theta= 1.$$ Será encontrado um teste da razão de verossimilhanças para $H_0$ com nível de significância $\alpha$ fixado. Primeiro, tem-se que
$$\log f(x_1|\theta)=-\log(\theta) - \frac{x}{\theta},$$
logo, é fácil mostrar que o EMV para $\theta$ é $\hat{\theta}=X_1$. Sob a hipótese nula, o único valor possível para $\theta$ é 1, logo $\hat{\theta}_0=1$ é o EMV sob esta hipótese. A estatística do TRV é
$$\lambda(X_1)=\frac{L(\hat{\theta}_0)}{L(\hat{\theta})}=X_1e^{-X_1 + 1} $$ 
e a região de rejeição deste teste é dada por 
$$\bm{R}=\{X_1>0:X_1e^{-X_1 + 1}<k\},$$
para algum $k\in(0,1)$. O valor de $k$ é escolhido de tal forma que
$$\alpha\geq P(\lambda(X_1)\leq k|\theta=1).$$
A figura abaixo mostra o esboço do gráfico de $\lambda(x)$ em função de $x_1$. 
\begin{center}
%\includegraphics[width=0.7\linewidth]{.~/Figuras/TRV_uma_exponencial}
\end{center}
Pode-se perceber que, para qualquer $k$ fixado existem $c_1$ e $c_2$ tais que 
$$\{\lambda(x)\leq k\}\Leftrightarrow \{x\leq c_1\}\cup\{x\geq c_2\}$$
logo,
\begin{align*}
\alpha &\geq P(X_1\leq c_1)+P(X_1\geq c_2)=1-e^{-c_1} + e^{-c_2}
\end{align*}
Portanto, o teste de nível $\alpha$ que rejeita $H_0$ se $\lambda(x_1)\leq k$ pode ser reescrito sem perda de generalidade como um teste que rejeita $H_0$ se $x_1\leq c_1$ ou $x_1\geq c_2$. Por exemplo, tomando $c_1$ e $c_2$ como sendo os valores que satisfazem 
$$P(X_1\leq c_1|\theta=1)=\frac{\alpha}{2}$$
e
$$P(X_1\geq c_2|\theta=1)=\frac{\alpha}{2}$$
tem-se que 
$$c_1 = -\log\left(1-\frac{\alpha}{2}\right)$$
e
$$c_2 = -\log\left(\frac{\alpha}{2}\right)$$
sendo o respectivo TRV de nível $\alpha$ dado por
$$D(x_1)=\left\{\begin{array}{ll}
1, & \hbox{ se }x_1\leq -\log(1-\alpha/2)\hbox{ ou }x_1\geq -\log(\alpha/2)\\
0, & c.c.
\end{array}\right.$$
\end{exem}


\textcolor{blue}{O exemplo a seguir foi corrigido no dia 01/07/2015.}
{\begin{exem}\label{exem::TRV_exponencial}Seja $X_1,\ldots,X_n$ uma amostra de vaiid com $X_1\sim\hbox{Exponencial}(\theta)$. Queremos testar $H_0:\theta\geq \theta_0$. Sabemos que o EMV para $\theta$ é $\hat{\theta}=1/\bar{X}$. Sob $H_0$, devemos maximizar a seguinte verossimilhança
$$L(\theta)=\theta^{n}e^{-\theta n \bar{x}}I(\theta\geq \theta_0).$$

Se $\theta_0\leq1/\bar{x}$ a função possui uma única moda no ponto $1/\bar{x}$, logo $\hat{\theta}_0=1/\bar{x}$.

Se $\theta_0 > 1/\bar{x}$ a função é monótona decrescente em $\theta$ e seu máximo será atingido em $\hat{\theta}_0=\theta_0$.

Portanto, teremos que $\hat{\theta}_0=\frac{1}{\bar{x}}
       I\left(\theta_0\leq \frac{1}{\bar{x}}\right)+
       \theta_0I \left(\theta_0>\frac{1}{\bar{x}}\right)$.
Se $\theta_0<1/\bar{X}$, a estatística do TRV será igual a um. Em caso contrário, 
\begin{align*}
\lambda({\bf X})&=\frac{L(\hat{\theta}_0)}{L(\hat{\theta})}=\left(\frac{\hat{\theta}_0}{\hat{\theta}}\right)^n \exp\left\{-n\bar{x}(\hat{\theta}_0-\hat{\theta})\right\}\\
&= 	\left(\theta_0\bar{x}\right)^n \exp\left\{-n\bar{x}\theta_0+n\right\}=\lambda^\star (\bar{x})\\
\end{align*}
A Figura \ref{fig::TRV_exponencial} mostra o gráfico de $\lambda^\star(\bar{x})$. Como $\lambda^\star(\bar{x})$ é monótona decrescente para $\bar{x}>1/\theta_0$, para qualquer $k\in(0,1)$ existe um único valor $c$ tal que
$$\bm{R}=\{\bm{x}\in\mathbb{R}_+^n:\lambda(\bm{x})<k\}\equiv\{ \bar{x}\in\mathbb{R}_+:\bar{x}>c\}$$

O valor de $c$ pode ser encontrado para qualquer nível de significância $\alpha$ desejado. Sabemos que, $\sum_{i=1}^{n}X_i\sim\hbox{Gama}(n,\theta)$, logo $\bar{X}\sim\hbox{Gama}(n,n\theta)$. Defina  $G=\bar{X}\theta\sim\hbox{Gama}(n,n)$ (note que a distribuição de $G$ não depende de $\theta$). Sob $H_0$, teremos
\begin{align*}
\alpha &\geq \sup_{\theta\in\Theta_0}P(\bm{X}\in \bm{R}|H_0)=\sup_{\theta\in\Theta_0}P\left(\theta\bar{X}>c\theta|\theta\geq \theta_0\right)\\
&=\sup_{\theta\in\Theta_0}P\left(G>c\theta\right)=P\left(G>c\theta_0\right).
\end{align*}
Seja $g_\gamma$ o valor que satisfaz $P(G> g_\gamma)=\gamma$. Então 
$$P\left(G> c\theta_0\right)=\alpha
\Rightarrow c\theta_0 = g_\alpha 
\Rightarrow c=\frac{g_{\alpha}}{\theta_0}.$$
Portanto, o TRV de nível $\alpha$ possui região de rejeição $$\bm{R}=\{\bar{x}\in\mathbb{R}_+: \bar{x}>g_{\alpha}/\theta_0\}.$$
\end{exem}

\begin{center}
\begin{figure}
%\includegraphics[scale=.5]{.~/Figuras/TRV_exponencial}
\caption{$\lambda({\bf X})$ vista como função de $\bar{X}$ para o TRV da exponencial apresentado no Exemplo \ref{exem::TRV_exponencial}.}\label{fig::TRV_exponencial}
\end{figure}
\end{center}

\begin{exem}[Teste $t$ Bilateral]\label{exem::teste_t_bilateral}\textcolor{red}{(Ainda não corrigi este exemplo)}Sejam $X_1,\ldots,X_n$ vaiid com $X_1|\bm{\theta}\sim\hbox{Normal}(\mu,\sigma^2)$. Consideremos a hipótese $H_0:\mu=\mu_0$. Sabemos que $\hat{\bm{\theta}}=(\bar{X},\hat{\sigma}^2)$, onde $\hat{\sigma}^2 =(n-1)S^2/n$. Sob $H_0$, temos que $\hat{\bm{\theta}}_0=(\mu_0,\sigma^2_0)$, onde 
$$\sigma^2_0=\frac{1}{n}\sum_{i=1}^{n}(X_i-\mu_0)^2.$$
Assim,
\begin{align*}
\lambda({\bf X})&=\frac{L(\hat{\theta}_0)}{L(\hat{\theta})}=\frac{(1/\sigma^2_0)^{n/2}\exp\left\{-\frac{1}{2\sigma^2}\sum_{i=1}^{n}(X_i-\mu_0)^2\right\}}{(1/\hat{\sigma}^2)^{n/2}\exp\left\{-\frac{(n-1)}{2}\right\}}\\
&\varpropto \left(\frac{\hat{\sigma}^2}{\sigma_0^2}\right)^{n/2}.
\end{align*}
Lembrando que $\sum_i(X_i-\mu_0)^2=\sum_i(X_i-\bar{X})^2+n(\bar{X}-\mu_0)^2$, a região de rejeição será dada por
\begin{align*}
R&=\{{\bf X}\in\mathbb{R}^n: \lambda({\bf X})<k_1\}\equiv \left\{{\bf X}\in\mathbb{R}^n: \left(\frac{\hat{\sigma}^2}{\sigma^2_0}\right)^{n/2}<k_1\right\}\\
&\equiv \left\{{\bf X}\in\mathbb{R}^n: \frac{\hat{\sigma}^2}{\hat{\sigma^2}+(\bar{X}-\mu_0)^2}<k_2\right\},\hbox{  onde }k_2=k_1^{2/n}\\
&\equiv \left\{{\bf X}\in\mathbb{R}^n: \frac{1}{1+\frac{(\bar{X}-\mu_0)^2}{\hat{\sigma}^2}}<k_2\right\}\\
&\equiv \left\{{\bf X}\in\mathbb{R}^n: \frac{1-k_2}{k_2}<\frac{(\bar{X}-\mu_0)^2}{\hat{\sigma}^2}\right\},\hbox{ fazendo }k_3=\frac{1-k_2}{k_2},\\
&\equiv \left\{{\bf X}\in\mathbb{R}^n: \left|\frac{(\bar{X}-\mu_0)}{\hat{\sigma}}\right|>k_3\right\}.
\end{align*}
O cálculo das constantes $k_1$, $k_2$ e $k_3$ foram realizados para que o leitor acompanhasse as contas. Na prática, a expressão que levou a estas constantes é irrelevante. Antes de darmos a forma final de nossa estatística de teste, sabemos que $\bar{X}$ e $S^2$ são independentes. Sabemos ainda que $\sqrt{n}(\bar{X}-\mu_0)/\sigma^2\sim\hbox{Normal}(0,1)$, que 
$$S^2\sim\hbox{Gama}\left(\frac{n-1}{2},\frac{n-1}{2\sigma^2}\right)\Rightarrow \frac{\hat{\sigma}^2}{\sigma^2}=\frac{n-1}{n}\frac{S^2}{\sigma^2}\sim\chi^2_{n-1},$$
e 
$$\frac{(\bar{X}-\mu_0)}{\hat{\sigma}/\sqrt{n-1}}=\frac{(\bar{X}-\mu_0)/\sigma}{\sqrt{\frac{1}{n}S^/\sigma^2}}=\sqrt{n}\frac{\bar{X}-\mu_0}{S}\sim t_{n-1}.$$
Assim,
\begin{align*}
R&\equiv \left\{{\bf X}\in\mathbb{R}^n: \left|\frac{(\bar{X}-\mu_0)}{\hat{\sigma}}\right|>k_3\right\}\equiv \left\{{\bf X}\in\mathbb{R}^n: \left|\sqrt{n}\frac{\bar{X}-\mu_0}{S}\right|>k_4\right\}.
\end{align*}
A estatística $T=\sqrt{n}(\bar{X}-\mu_0)/S$ será nossa estatística de teste. Seja $t_\gamma$ o valor da distribuição $T\sim t_(n-1)$ tal que $P(T\leq t_\gamma)=\gamma$. Fixando o nível de significância em $\alpha$, e lembrando que a distribuição $t$ é simétrica em torno de zero, teremos
\begin{align*}
\alpha&=P\left({\bf X}\in R|H_0\right)=P\left(|T|>k_4\right)\\
&=P(T>k_4)+P(T<-k_4)= 2P(T< -k_4)\\
\end{align*}
logo $\alpha/2=P(T<-k_4)\Rightarrow -k_4=t_{\alpha/2}$. Notando que $-t_{\alpha/2}=t_{1-\alpha/2}$. Assim a região de rejeição do TRV de nível $\alpha$ é dada por
$$R=\{{\bf X}\in\mathbb{R}: |T|>t_{1-\alpha/2}\}.$$
Este teste é denominado {\bf Teste $t$ Bilateral}.
\end{exem}


## A função poder e os testes mais poderosos